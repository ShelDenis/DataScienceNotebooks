# -*- coding: utf-8 -*-
"""ExamML_Шелепов_B.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RWjMfk9IGekSSSHuAdukUESnxD-vu5C7

# Модуль B
"""

import pandas as pd

data_filtered = pd.read_csv('rotation_prepared.csv')
data_filtered = data_filtered.drop(['Unnamed: 0'], axis = 1)
data_filtered

"""Масшстабирование данных"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
y = data_filtered['Rotational speed [rpm]']
X = data_filtered.drop(['Rotational speed [rpm]', 'Product ID'], axis=1)

scaled_X = pd.DataFrame(scaler.fit_transform(X), columns=scaler.get_feature_names_out())
scaled_X

"""Понижение размерности"""

from sklearn.tree import DecisionTreeRegressor
from matplotlib import pyplot as plt

tree = DecisionTreeRegressor().fit(scaled_X, y)

plt.barh(width=tree.feature_importances_, y =X.columns )

"""Оставляем 5 признаков"""

from sklearn.feature_selection import SelectKBest

skb = SelectKBest(k=5)
skb_x = skb.fit_transform(scaled_X, y)
skb_X = pd.DataFrame(skb_x, columns=skb.get_feature_names_out())
skb_X

all_df = pd.concat([skb_X, y], axis=1)
all_df



"""## Выбор модели ML

Используем 3 модели регрессии:

1) Линейная регрессия

2) DecisionTreeRegressor

3) GradientBoostingRegressor

Данные регрессоры были выбраны из-за неочевидности линейной зависимости целевого признака от переменных. Да, Скорость вращения сильно зависит от крутящего момента (проверим точностью модели линейной регрессии), но также есть факторы как различные поломки (нам помогут DecisionTreeRegressor и GradientBoostingRegressor)
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(skb_X, y, test_size=0.2)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def get_metrics(y_test, y_pred):
  print(f'MSE: {mean_squared_error(y_test, y_pred)}')
  print(f'MAE: {mean_absolute_error(y_test, y_pred)}')
  print(f'R2: {r2_score(y_test, y_pred)}')

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)
get_metrics(y_test, y_pred)

from sklearn.model_selection import RandomizedSearchCV

params = {
    'fit_intercept': [True, False],
    'copy_X': [True, False],
}

rscv = RandomizedSearchCV(LinearRegression(), params, cv=5, n_iter=10)
rscv.fit(X_train, y_train)

best_params = rscv.best_params_
best_lr = rscv.best_estimator_

print(best_params)

best_lr.fit(X_train, y_train)
y_pred = best_lr.predict(X_test)
get_metrics(y_test, y_pred)

from sklearn.tree import DecisionTreeRegressor

ltree = DecisionTreeRegressor()

ltree.fit(X_train, y_train)
y_pred = ltree.predict(X_test)
get_metrics(y_test, y_pred)

params = {
    'criterion' :['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],
    'max_depth' : list(range(1, 11))
}

rscv = RandomizedSearchCV(DecisionTreeRegressor(), params, cv=5, n_iter=10)
rscv.fit(X_train, y_train)

best_params = rscv.best_params_
best_tree = rscv.best_estimator_

print(best_params)

best_tree.fit(X_train, y_train)
y_pred = best_tree.predict(X_test)
get_metrics(y_test, y_pred)

from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor()

gbr.fit(X_train, y_train)
y_pred = gbr.predict(X_test)
get_metrics(y_test, y_pred)

params = {
    'loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],
    'max_depth' : list(range(1, 11, 2)),
    'n_estimators': [100, 200, 300, 500],
}

rscv = RandomizedSearchCV(GradientBoostingRegressor(), params, cv=5, n_iter=5)
rscv.fit(X_train, y_train)

best_params = rscv.best_params_
best_gbr = rscv.best_estimator_

print(best_params)

best_gbr.fit(X_train, y_train)
y_pred = best_gbr.predict(X_test)
get_metrics(y_test, y_pred)

"""###  Вывод:

Наилучшая модель - GradientBoostingRegressor (с минимальным MSE = 2544)

Произведем деплой этой модели
"""

my_line = pd.DataFrame(columns=['Torque [Nm]',	'Machine failure',	'HDF',	'PWF',	'OSF'], data=[[45, 0, 1, 0, 1]])

scaled_my_line = scaler.fit_transform(my_line)

prediction = best_gbr.predict(scaled_my_line)[0]
prediction